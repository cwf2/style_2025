{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cwf2/style_2025/blob/main/Assignment%202b%20-%20pronouns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa60504f-7cc9-4fd3-aa46-9127cb6de7f1",
      "metadata": {
        "id": "aa60504f-7cc9-4fd3-aa46-9127cb6de7f1"
      },
      "source": [
        "# Assignment: pronouns\n",
        "\n",
        "In this assignment we look at the use of pronouns in two speeches: Calypso to Odysseus at *Odyssey* 5.203-5.213 and Dido to Aeneas at *Aeneid* 4.305-4.330.\n",
        "\n",
        "The first section fast-forwards through the same steps as the **Example 2** notebook, skipping some of the longer explanations. If you're continuing from that point, you can skip ahead to [Section 3](#3.-Part-of-speech-counts) below.\n",
        "\n",
        "## 1. Preliminaries\n",
        "\n",
        "### Install DICES client software\n",
        "\n",
        "Because Google Colab runs this notebook on a fresh virtual machine every time, we always need to install DICES as the first step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a849d166-8505-451a-bdee-e8b2bf50121d",
      "metadata": {
        "id": "a849d166-8505-451a-bdee-e8b2bf50121d"
      },
      "outputs": [],
      "source": [
        "# revert pip for language model compatibility\n",
        "!pip install -q --force-reinstall pip==22.0.0\n",
        "# install DICES client\n",
        "!pip install -q git+https://github.com/cwf2/dices-client\n",
        "# install language models\n",
        "!pip install -q https://huggingface.co/latincy/la_core_web_md/resolve/main/la_core_web_md-any-py3-none-any.whl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebe2ce39-1a82-4145-8e56-dfe49c2e5cc8",
      "metadata": {
        "id": "ebe2ce39-1a82-4145-8e56-dfe49c2e5cc8"
      },
      "source": [
        "### Import statements\n",
        "\n",
        "Here we tell Python which ancillary packages we want to make accessible. In this case, the DICES client and Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51bf88b6-9143-4b07-a02c-c48f6d575840",
      "metadata": {
        "id": "51bf88b6-9143-4b07-a02c-c48f6d575840"
      },
      "outputs": [],
      "source": [
        "# for talking to DICES\n",
        "from dicesapi import DicesAPI\n",
        "# for talking to Perseus\n",
        "from dicesapi.text import CtsAPI\n",
        "# for creating data tables\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "778f54a8-14f7-42eb-b10c-f0ebe62e4824",
      "metadata": {
        "id": "778f54a8-14f7-42eb-b10c-f0ebe62e4824"
      },
      "source": [
        "### Connect to external resources\n",
        "Here we instantiate connections to the DICES database and to the Perseus Digital Library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "216d02c2-a115-41f8-b758-b54d6f27295e",
      "metadata": {
        "id": "216d02c2-a115-41f8-b758-b54d6f27295e"
      },
      "outputs": [],
      "source": [
        "# create a new DICES connection\n",
        "api = DicesAPI(logfile=\"dices.log\", logdetail=0)\n",
        "\n",
        "# create a new CTS connection\n",
        "cts = CtsAPI(dices_api=api)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cee2d000-9269-49df-ada1-2a180f8e1a53",
      "metadata": {
        "id": "cee2d000-9269-49df-ada1-2a180f8e1a53"
      },
      "source": [
        "## 2. Download speeches\n",
        "\n",
        "It's a little hard to request these exact speeches from DICES. I'm going to:\n",
        "\n",
        "- request all speeches by Calypso to Odysseus\n",
        "- request all speeches by Dido to Aeneas\n",
        "- add the results together\n",
        "- look at them manually and note the IDs of the speeches I want\n",
        "- filter the results for just those IDs\n",
        "\n",
        "### Get speeches from DICES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "279fa700-20d6-4f43-8866-a530a113b8ee",
      "metadata": {
        "id": "279fa700-20d6-4f43-8866-a530a113b8ee"
      },
      "outputs": [],
      "source": [
        "# download metadata on speeches by women in the Odyssey and the Aeneid\n",
        "speeches = (\n",
        "    api.getSpeeches(spkr_name=\"Calypso\", addr_name=\"Odysseus\") +\n",
        "    api.getSpeeches(spkr_name=\"Dido\", addr_name=\"Aeneas\")\n",
        ").sorted()\n",
        "\n",
        "# check that it worked\n",
        "print(len(speeches), \"speeches.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffe4a792-f12e-42f5-adf1-4575ee499e57",
      "metadata": {
        "id": "ffe4a792-f12e-42f5-adf1-4575ee499e57"
      },
      "source": [
        "### Make a speech table\n",
        "\n",
        "Here we create a Pandas data frame from our results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f29d05ae-b610-42b3-a7ec-069b5bcb40d0",
      "metadata": {
        "id": "f29d05ae-b610-42b3-a7ec-069b5bcb40d0"
      },
      "outputs": [],
      "source": [
        "# an empty list of rows\n",
        "rows = []\n",
        "\n",
        "# iterate over all speeches\n",
        "for speech in speeches:\n",
        "\n",
        "    # create a new row\n",
        "    row = {\n",
        "        \"speech_id\": speech.id,\n",
        "        \"language\": speech.lang,\n",
        "        \"author\": speech.author.name,\n",
        "        \"work\": speech.work.title,\n",
        "        \"first_line\": speech.l_fi,\n",
        "        \"last_line\": speech.l_la,\n",
        "        \"speaker\": speech.getSpkrString(),\n",
        "        \"address\": speech.getAddrString(),\n",
        "    }\n",
        "\n",
        "    # add row to the list\n",
        "    rows.append(row)\n",
        "\n",
        "# make a table\n",
        "speech_table = pd.DataFrame(rows)\n",
        "\n",
        "# display\n",
        "display(speech_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebe306bd-dddc-4750-ba13-a5043663cd49",
      "metadata": {
        "id": "ebe306bd-dddc-4750-ba13-a5043663cd49"
      },
      "source": [
        "### Filter on ID\n",
        "\n",
        "From the table, I can see that the speeches I want have IDs 820 and 1610. I'm going to create a new group with just those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e841d672-34fd-456b-9428-a6cddefe1432",
      "metadata": {
        "id": "e841d672-34fd-456b-9428-a6cddefe1432"
      },
      "outputs": [],
      "source": [
        "# filter on ID\n",
        "farewells = speeches.filterIDs([820, 1610])\n",
        "\n",
        "# check that it worked\n",
        "for speech in farewells:\n",
        "    print(speech)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c31a8ca-292c-4c96-8ece-90cc8525d115",
      "metadata": {
        "id": "3c31a8ca-292c-4c96-8ece-90cc8525d115"
      },
      "source": [
        "### Download the text from Perseus\n",
        "\n",
        "Next, I'm going to download the text of both speeches from Perseus using the CTS connection I created earlier. The `getPassage()` method takes a DICES speech as its argument and returns the corresponding passage from Perseus. I'll save the passage as a new attribute of the the speech object to make sure that the speech and its text stay together.\n",
        "\n",
        "It's important to check that this step works... a few speeches in Perseus don't work well with CTS yet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e11040c7-fdc4-4f3e-91e1-45e69959e20d",
      "metadata": {
        "id": "e11040c7-fdc4-4f3e-91e1-45e69959e20d"
      },
      "outputs": [],
      "source": [
        "# loop over two farewell speeches\n",
        "for speech in farewells:\n",
        "    # download the text from perseus\n",
        "    speech.passage = cts.getPassage(speech)\n",
        "\n",
        "    # display the results\n",
        "    print(speech, \"\\n\")\n",
        "    print(speech.passage.text, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db8a8980-5127-4339-990e-ae0a348c977b",
      "metadata": {
        "id": "db8a8980-5127-4339-990e-ae0a348c977b"
      },
      "source": [
        "### Parse the text using natural language processing\n",
        "\n",
        "In this step, we process the downloaded text of the speeches using NLP. The method `runSpacyPipeline()` runs the appropriate spaCy pipeline based on the passage's language and saves the output to a new attribute called `spacy_doc`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bebd419b-787b-493d-acfb-7a7964a1bc45",
      "metadata": {
        "id": "bebd419b-787b-493d-acfb-7a7964a1bc45"
      },
      "outputs": [],
      "source": [
        "# loop over two farewell speeches\n",
        "for speech in farewells:\n",
        "    # run spacy\n",
        "    speech.passage.runSpacyPipeline()\n",
        "\n",
        "    # check that it worked\n",
        "    print(speech, len(speech.passage.spacy_doc), \"tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "659bb022-193c-4972-b2b9-8792f73a10d6",
      "metadata": {
        "id": "659bb022-193c-4972-b2b9-8792f73a10d6"
      },
      "source": [
        "### Create a table of tokens\n",
        "\n",
        "This code creates a table with one row per token. Using nested `for` loops, we take each speech in turn, then each token of that speech. We build a record for the row that incorporates information about the speech and the token. At the end, we turn the list of rows into a Pandas data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c6240a5-9cac-4c89-9d9b-84f8c6da54a5",
      "metadata": {
        "id": "0c6240a5-9cac-4c89-9d9b-84f8c6da54a5"
      },
      "outputs": [],
      "source": [
        "# start with an empty list of rows\n",
        "rows = []\n",
        "\n",
        "# iterate over speeches\n",
        "for speech in farewells:\n",
        "\n",
        "    # iterate over tokens\n",
        "    for token in speech.passage.spacy_doc:\n",
        "\n",
        "        # create a record for this token\n",
        "        row = {\n",
        "            \"speech_id\": speech.id,\n",
        "            \"language\": speech.lang,\n",
        "            \"author\": speech.author.name,\n",
        "            \"title\": speech.work.title,\n",
        "            \"book\": speech.getPrefix(),                       # see note 1 below\n",
        "            \"line\": speech.passage.getLine(token)[\"n\"],       # see note 2\n",
        "            \"speaker\": speech.getSpkrString(),\n",
        "            \"addressee\": speech.getAddrString(),\n",
        "            \"token\": token.text,\n",
        "            \"lemma\": token.lemma_,\n",
        "            \"pos\": token.pos_,\n",
        "            \"verbform\": ''.join(token.morph.get(\"VerbForm\")), # see note 3\n",
        "            \"mood\": ''.join(token.morph.get(\"Mood\")),\n",
        "            \"voice\": ''.join(token.morph.get(\"Voice\")),\n",
        "            \"tense\": ''.join(token.morph.get(\"Tense\")),\n",
        "            \"person\": ''.join(token.morph.get(\"Person\")),\n",
        "            \"case\": ''.join(token.morph.get(\"Case\")),\n",
        "            \"gender\": ''.join(token.morph.get(\"Gender\")),\n",
        "            \"number\": ''.join(token.morph.get(\"Number\")),\n",
        "        }\n",
        "\n",
        "        # add row to the list of rows\n",
        "        rows.append(row)\n",
        "\n",
        "# convert to a table\n",
        "tokens = pd.DataFrame(rows)\n",
        "\n",
        "# write the tokens to a CSV file\n",
        "tokens.to_csv(\"tokens.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "# display the table\n",
        "display(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfd09f60-0bc7-40fc-8ab6-26ef296f32c6",
      "metadata": {
        "id": "bfd09f60-0bc7-40fc-8ab6-26ef296f32c6"
      },
      "source": [
        "## 3. Part-of-speech counts\n",
        "\n",
        "Beginning from the token table, we can create counts of any feature using `groupby()` and `agg()`. Note that both the Latin and Greek models are using [Universal Part of Speech](https://universaldependencies.org/u/pos/) tags. In theory, this should allow at least some cross-language comparison.\n",
        "\n",
        "### Basic counts\n",
        "\n",
        "This is the same sort of data manipulation we did in the first half of the workshop. We're grouping by two factors, speaker and part-of-speech. We want our summary table to have rows drawn from the values of **speaker** and columns from the values of **pos**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "940da6b4-6434-47b0-8458-ce653005d214",
      "metadata": {
        "id": "940da6b4-6434-47b0-8458-ce653005d214"
      },
      "outputs": [],
      "source": [
        "# part of speech usage by character\n",
        "pos = (\n",
        "    tokens                            # original data\n",
        "    .groupby([\"speaker\", \"pos\"])      # group by character\n",
        "    .agg(                             # define new table\n",
        "        count = (\"token\", \"count\"),   #   - token count\n",
        "    )\n",
        "    .unstack()                        # move second factor to columns\n",
        "    .fillna(0)                        # add zeros for missing data\n",
        "    .astype(int)                      # convert to integer (since counts are whole numbers)\n",
        ")\n",
        "\n",
        "# show results\n",
        "display(pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2add0ae-98a0-43dd-9cf6-7c9187c36e5d",
      "metadata": {
        "id": "b2add0ae-98a0-43dd-9cf6-7c9187c36e5d"
      },
      "source": [
        "**Notes**\n",
        "\n",
        "- If a given part of speech occurs only in one speaker, the default (stacked) version of the table will just leave it out for the other speaker. But when we `unstack()` to move POS tags to columns, then something has to go in the cell for that column. Pandas defaults to puting `NaN`, representing missing data. Sometimes `NaN` is the best answer, but in this case we can safely replace missing values with zeros.\n",
        "- Another default of Pandas is to use *floating-point* values (i.e. numbers with a decimal) in summary tables. Because all our counts are necessarily whole numbers, the decimal doesn't make sense. I'm adding a line to force the whole table to integer format."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "def9b62d-4a5e-48e0-863a-450e9cc39131",
      "metadata": {
        "id": "def9b62d-4a5e-48e0-863a-450e9cc39131"
      },
      "source": [
        "### Converting to frequencies\n",
        "\n",
        "Since the two speeches are different lengths, it makes sense to convert raw counts to frequencies. We'll represent these as per 1000 words to keep the numbers manageable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61d580f2-2b16-4788-a2df-25add7ea7bfa",
      "metadata": {
        "id": "61d580f2-2b16-4788-a2df-25add7ea7bfa"
      },
      "outputs": [],
      "source": [
        "# calculate total number of tokens for each speech\n",
        "totals = pos.apply(sum, axis=1)\n",
        "\n",
        "# divide each value in each row by the respective total\n",
        "pos_freq = (\n",
        "    pos[\"count\"]              # needed because column names have two levels\n",
        "    .div(totals, axis=0)      # divide by totals, row-wise\n",
        "    .multiply(1000)           # convert to freq per 1000 words\n",
        "    .round(1)                 # round answer to 1 decimal\n",
        ")\n",
        "\n",
        "# show results\n",
        "display(pos_freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f4d3831-c5dd-450c-9581-21d5997f28ad",
      "metadata": {
        "id": "5f4d3831-c5dd-450c-9581-21d5997f28ad"
      },
      "source": [
        "Now we can see more clearly that, for example, while Calypso uses fewer adjectives in absolute terms, they represent a larger proportion of her speech. Nouns and verbs, meanwhile, seem relatively similar between the two speeches.\n",
        "\n",
        "Some things, like adverbs, will depend a lot on the difference between the languages and the behaviour of the models. It's worth looking more closely to see what is included in these tags.\n",
        "\n",
        "As for pronouns, the subject of our interest here, Dido uses more both in absolute terms and proportionally."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1be54716-ed3a-44b6-b519-1d4fc4535e5f",
      "metadata": {
        "id": "1be54716-ed3a-44b6-b519-1d4fc4535e5f"
      },
      "source": [
        "### A little concordance of pronouns\n",
        "\n",
        "Let's create a list of pronouns used by each speaker. We'll count how often each pronoun is used, and include a list of the forms it takes and where it occurs in the speech."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dc0e2f2-b47c-43d0-bddc-5bdc34f66fee",
      "metadata": {
        "id": "8dc0e2f2-b47c-43d0-bddc-5bdc34f66fee"
      },
      "outputs": [],
      "source": [
        "# create a concordance of pronouns\n",
        "conc = (\n",
        "    tokens                                 # start with full token table\n",
        "    .query(\"pos=='PRON'\")                  # keep only pronouns\n",
        "    .groupby([\"speaker\", \"lemma\"])         # group by speaker and lemma\n",
        "    .agg(                                  # define new summary table\n",
        "        count = (\"token\", \"count\"),        #  - count of tokens per lemma\n",
        "        forms = (\"token\", \"unique\"),       #  - list of all unique forms\n",
        "        lines = (\"line\", \"unique\"),        #  - list of loci\n",
        "    )\n",
        "    .sort_values([\"speaker\", \"count\"], ascending=False) # sort results\n",
        ")\n",
        "\n",
        "display(conc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edadf6cd-9c57-4480-a9f2-eeca71d4413d",
      "metadata": {
        "id": "edadf6cd-9c57-4480-a9f2-eeca71d4413d"
      },
      "source": [
        "### Distribution within the speeches\n",
        "\n",
        "While our little concordance gives us some sense of the pronouns' distributions in their respective speeches, it can be hard to visualize. Let's count pronouns per line so we can get a clearer picture of where they are in the speech."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab6b195d-e5d9-47aa-9cd5-9c2e96c038b8",
      "metadata": {
        "id": "ab6b195d-e5d9-47aa-9cd5-9c2e96c038b8"
      },
      "outputs": [],
      "source": [
        "# create a table of POS counts per line\n",
        "pos_by_line = (\n",
        "    tokens                                # original token table\n",
        "    .query(f\"speaker=='Calypso'\")         # filter by speaker name\n",
        "    .groupby([\"line\", \"pos\"])             # group line by line\n",
        "    .agg(                                 # define new table\n",
        "        count = (\"token\", \"count\"),       #  - tokens per line\n",
        "    )\n",
        "    .unstack()          # move pos to columns\n",
        "    .fillna(0)          # fill missing values with zero\n",
        "    .astype(int)        # convert to whole numbers\n",
        ")\n",
        "\n",
        "# drop the extra \"count\" level in the column names\n",
        "pos_by_line = pos_by_line[\"count\"]\n",
        "\n",
        "# show results\n",
        "display(pos_by_line)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f607388c-724e-4267-8fcd-3dfd34b69765",
      "metadata": {
        "id": "f607388c-724e-4267-8fcd-3dfd34b69765"
      },
      "source": [
        "### Graph distribution\n",
        "\n",
        "Now let's graph the resulting distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "902a53bc-ee12-4422-a25d-e89f02a69456",
      "metadata": {
        "id": "902a53bc-ee12-4422-a25d-e89f02a69456"
      },
      "outputs": [],
      "source": [
        "# display a bar plot of PRON counts\n",
        "pos_by_line[\"PRON\"].plot.bar(title=\"Calypso\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e002f794-6644-4ca2-8369-69db24cdbc66",
      "metadata": {
        "id": "e002f794-6644-4ca2-8369-69db24cdbc66"
      },
      "source": [
        "#### Likewise for Dido..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4b05c01-3b6f-43d3-8fa2-44d607a44259",
      "metadata": {
        "id": "e4b05c01-3b6f-43d3-8fa2-44d607a44259"
      },
      "outputs": [],
      "source": [
        "# create a table of POS counts per line\n",
        "pos_by_line = (\n",
        "    tokens                                # original token table\n",
        "    .query(f\"speaker=='Dido'\")            # filter by speaker name\n",
        "    .groupby([\"line\", \"pos\"])             # group line by line\n",
        "    .agg(                                 # define new table\n",
        "        count = (\"token\", \"count\"),       #  - tokens per line\n",
        "    )\n",
        "    .unstack()          # move pos to columns\n",
        "    .fillna(0)          # fill missing values with zero\n",
        "    .astype(int)        # convert to whole numbers\n",
        ")\n",
        "\n",
        "# drop the extra \"count\" level in the column names\n",
        "pos_by_line = pos_by_line[\"count\"]\n",
        "\n",
        "# display a bar plot of PRON counts\n",
        "pos_by_line[\"PRON\"].plot.bar(title=\"Dido\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}